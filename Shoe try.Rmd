---
title: "Shoe try"
author: "Blake Lin"
date: "4/21/2022"
output: html_document
---

## Discussion Note
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(zoo)
library(usmap)
library(rpart)
library(rpart.plot)
library(rsample) 
library(randomForest)
library(modelr)
library(caret)
library(gamlr)
```


### Explain Variables
`sporting_goods`: Monthly Seasonally Adjusted Sales (in Millions of Dollars) in Advance Monthly Sales for Retail and Food Services: U.S. Total

`monthly_retail`: Monthly Seasonally Adjusted Sales (in Millions of Dollars) in Sporting Goods, Hobby, Musical Instrument, and Book Stores: U.S. Total

`sp_index`: the index comprises stocks in the S&P total market index that are classified as in the GICS retail sub-industry


```{r visualizations, echo=FALSE, dpi=300}
shoe_data <- read.csv("data/shoe_final.csv")


#We'll look at the total sales per month and the cumulative sum for each brand over time
sales_dollars = shoe_data %>%
  group_by(brand, Year_month) %>%
  summarise(monthly_sales = sum(sale_price))
sales_dollars = sales_dollars %>%
  group_by(brand) %>%
  mutate(total_sales = cumsum(monthly_sales))


ggplot(sales_dollars) +
  geom_line(aes(x=Year_month,y=monthly_sales, group = brand, color = brand))

ggplot(sales_dollars) +
  geom_line(aes(x=Year_month,y=total_sales, group = brand, color = brand))


# Next we'll look at total sales volume (number of orders) per month as well as cumulative orders over time.

sales_vol = shoe_data %>%
  group_by(brand, Year_month) %>%
  summarise(monthly_orders = n())
sales_vol = sales_vol %>%
  group_by(brand) %>%
  mutate(total_orders = cumsum(monthly_orders))

ggplot(sales_vol) +
  geom_line(aes(x=Year_month,y=monthly_orders, group = brand, color = brand))

ggplot(sales_vol) +
  geom_line(aes(x=Year_month,y=total_orders, group = brand, color = brand))



```


We see a spike in orders during the holidays for both brands. The bulk of the orders as well as sales dollars comes from Yeezys most likely because the Adidas Yeezy shoes are cheaper on the resale market than the more exclusive Nike Off-White shoes.


```{r visualizations2, echo=FALSE, dpi=300}
shoe_data$resale_premium = shoe_data$sale_price - shoe_data$retail_price
shoe_data$resale_premium_percent = 100*(shoe_data$resale_premium / shoe_data$retail_price)

brand_premium = shoe_data %>%
  group_by(brand, Year_month) %>%
  summarise(average_premium = mean(resale_premium_percent))

ggplot(brand_premium) +
  geom_line(aes(x=Year_month,y=average_premium, group = brand, color = brand))

time_elapse = shoe_data %>%
  mutate(time_stamp2=mdy(shoe_data$release_date), .before=release_date)

time_elapse$time_elapsed = as.numeric(as.Date(time_elapse$time_stamp) - as.Date(time_elapse$time_stamp2))

time_elapse$time_elapsed[time_elapse$time_elapsed < 0] <- 0

time_elapse = time_elapse%>%
  select(resale_premium, resale_premium_percent, brand, time_elapsed)

ggplot(time_elapse) +
  geom_point(aes(x=time_elapsed,y=resale_premium, group = brand, color = brand)) +
  xlab("Days Between Order Date and Release Date") +
  ylab("Resale Premium")

ggplot(time_elapse) +
  geom_point(aes(x=time_elapsed,y=resale_premium_percent, group = brand, color = brand)) +
  xlab("Days Between Order Date and Release Date") +
  ylab("Percent Resale Premium")
  
  

```

For Yeezys, buyers typically paid a ~200% premium for resale while Off-White buyers paid on average ~600%. For both brands the resale prices cooled off, but the Off-White shoes still demanded a much higher average premium throughout. We think this is the case because Adidas tends to restock their shoes much more frequently to the point where some shoes like the `adidas-Yeezy-Boost-350-V2-Butter` or the `Adidas-Yeezy-Boost-350-V2-Cream-White` resell for less than their retail price.


```{r visualizations3, echo=FALSE, dpi=300}

# We're looking at a sales premium percent change
resale_prem = shoe_data %>%
  group_by(year = year(time_stamp), buyer_region) %>%
  summarise(avg_resale_premium = mean(resale_premium_percent)) %>%
  select(state = buyer_region, year, avg_resale_premium)

total_order_count = shoe_data %>%
  group_by(year = year(time_stamp), buyer_region) %>%
  summarise(total_order_count = n()) %>%
  select(state = buyer_region, year, total_order_count)

state_pop_income = distinct(shoe_data %>%
                              group_by(buyer_region, year) %>%
                              select(year, buyer_region, State_pop_year, disposable_per_cap_income) %>%
                              arrange(buyer_region, year))

state_year_aggs = merge(merge(resale_prem, total_order_count, by = c("state", "year")), state_pop_income, by.x = c("state","year"), by.y=c("buyer_region","year"), all.x = TRUE)



## resale premium
map_1 = plot_usmap(data = state_year_aggs %>% filter(year=="2017"), values = "avg_resale_premium", color = "black") + 
  scale_fill_continuous(low = "white", high = "blue", name = "Average Resale Premium", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2017 Average Resale Premium by State")

map_2 = plot_usmap(data = state_year_aggs %>% filter(year=="2018"), values = "avg_resale_premium", color = "black") + 
  scale_fill_continuous(low = "white", high = "blue", name = "Average Resale Premium", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2018 Average Resale Premium by State")

map_3 = plot_usmap(data = state_year_aggs %>% filter(year=="2019"), values = "avg_resale_premium", color = "black") + 
  scale_fill_continuous(low = "white", high = "blue", name = "Average Resale Premium", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2019 Average Resale Premium by State")

map_1
map_2
map_3

## total orders

# column is in millions so we gotta * 1000000
state_year_aggs$State_pop_year = state_year_aggs$State_pop_year*1000000
state_year_aggs$orders_per_capita = state_year_aggs$total_order_count / state_year_aggs$State_pop_year
state_year_aggs$orders_per_10000 = 10000*(state_year_aggs$total_order_count / state_year_aggs$State_pop_year)
state_year_aggs$orders_income_fixed = (state_year_aggs$total_order_count / state_year_aggs$disposable_per_cap_income)

map_4 = plot_usmap(data = state_year_aggs %>% filter(year=="2017"), values = "orders_per_10000", color = "red") + 
  scale_fill_continuous(low = "white", high = "orange", name = "Orders", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2017 Total Order Count per 10000")

map_5 = plot_usmap(data = state_year_aggs %>% filter(year=="2018"), values = "orders_per_10000", color = "red") + 
  scale_fill_continuous(low = "white", high = "orange", name = "Orders", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2018 Total Order Count per 10000")

map_6 = plot_usmap(data = state_year_aggs %>% filter(year=="2019"), values = "orders_per_10000", color = "red") + 
  scale_fill_continuous(low = "white", high = "orange", name = "Orders", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2019 Total Order Count per 10000")


map_4
map_5
map_6 #oregon emerges as a major sneaker buyer market

# holding income fixed, we'll see if oregon still stands out
map_7 = plot_usmap(data = state_year_aggs %>% filter(year=="2019"), values = "orders_income_fixed", color = "red") + scale_fill_continuous(low = "white", high = "orange", name = "Orders", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2019 Total Order Count per capita")

map_7 #oregon is still special 
```



```{r correlation, echo=FALSE, dpi=300}
X = shoe_data %>%
  select(resale_premium_percent, sp_index, sporting_goods.x)

ggcorrplot::ggcorrplot(cor(X), hc.order = TRUE)
```





```{r prediction model, cache=TRUE, echo=FALSE}
premium_data = shoe_data %>%
  mutate(premium = (sale_price - retail_price)/retail_price) %>%
  mutate_if(is.character, as.factor)

# split data into training and testing
set.seed(349385)
premium_split = initial_split(premium_data, prop=0.8)
premium_train = training(premium_split)
premium_test  = testing(premium_split)

# a single tree
premium_tree = rpart(premium ~ brand + sneaker_name + shoe_size + buyer_region + Year_month  + primary_color + secondary_color + Material, data = premium_train,
                    control = rpart.control(cp = 0.02, minsplit=300), maxdepth = 4)

#rpart.plot(premium_tree, digits=-5, type=4, extra=1)

# forest 
premium_forest = randomForest(premium ~ brand + sneaker_name + shoe_size + buyer_region + Year_month  + primary_color + secondary_color + Material, data=premium_train, control = rpart.control(cp = 0.002), ntrees = 300, importance=TRUE, na.action = na.omit)

# variable importance measures
vi = varImpPlot(premium_forest, type=1)

# # forest pd plots
partialPlot(premium_forest, premium_test, 'Year_month', las=1)
partialPlot(premium_forest, premium_test, 'shoe_size', las=1)
partialPlot(premium_forest, premium_test, 'sneaker_name', las=1)

# finished model building: compare RMSE
rmse_premium_tree = rmse(premium_tree, premium_test)
rmse_premium_forest = rmse(premium_forest, premium_test)

rmse_premium_tree
rmse_premium_forest
```






### Reference 
##### S&P Retail Select Industry Index
https://www.spglobal.com/spdji/en/indices/equity/sp-retail-select-industry-index/#overview

##### US Census Bureau
https://www.census.gov/retail/marts/historic_releases.html

