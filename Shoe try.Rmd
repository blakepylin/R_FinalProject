---
title: "Shoe try"
author: "Blake Lin"
date: "4/21/2022"
output: html_document
---

## Discussion Note
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(zoo)

monthly_retail_df <- read_csv("data/monthly_retail.csv")
monthly_retail_df1 <- read_csv("data/monthly_retail.csv")
sp_index_df <- read_csv("data/sp_index_df.csv")
state_pop_income <- read_csv("data/state_pop_income.csv")
shoe_data <- read_csv("data/shoe_data.csv")


#Demographic
  # state population
  # state income

#Market Trend
  # ETF price - consumer good/ S&P 500
  # retail sales trend - US Census Bureau

#Popularity
  #Team performance
  #google search trend
  #social media
  #Kayne's song on chart 

#Product
  # Shoe dimension
  # material

# Branden: data analysis: https://thehustle.co/shark-tank-data-analysis-10-seasons/
# Blake: random forest, linear (lasso) on premium
# Jayme: variable, introduction
```



### Explain Variables
`sporting_goods`: Monthly Seasonally Adjusted Sales (in Millions of Dollars) in Advance Monthly Sales for Retail and Food Services: U.S. Total

`monthly_retail`: Monthly Seasonally Adjusted Sales (in Millions of Dollars) in Sporting Goods, Hobby, Musical Instrument, and Book Stores: U.S. Total

`sp_index`: the index comprises stocks in the S&P total market index that are classified as in the GICS retail sub-industry




### Data Cleaning 
```{r data cleaning, echo=FALSE}

# put on time stamp for every data sets
shoe_data = shoe_data %>% 
  mutate(time_stamp=mdy(shoe_data$order_date), .before=order_date)
shoe_data$year = year(shoe_data$time_stamp)

#drop commas and dollar signs
shoe_data$sale_price = as.numeric(gsub("[\\$,]", "", shoe_data$sale_price))
shoe_data$retail_price = as.numeric(gsub("[\\$,]", "", shoe_data$retail_price))
state_pop_income$disposable_per_cap_income = as.numeric(gsub("[\\$,]", "", state_pop_income$disposable_per_cap_income))


#sporting good index
monthly_retail_df=monthly_retail_df %>% 
  mutate(time_stamp=mdy(Period), .before = Period)
monthly_retail_df = monthly_retail_df[ ,-(2)]

monthly_retail_df = monthly_retail_df%>%
group_by(time_stamp) %>%
expand(time_stamp = seq(floor_date(time_stamp, unit = "month"),
       ceiling_date(time_stamp, unit="month")-days(1), by="day"), sporting_goods) %>% as.data.frame()

# retail monthly index
monthly_retail_df1=monthly_retail_df1 %>% 
  mutate(time_stamp=mdy(Period), .before = Period)
monthly_retail_df1 = monthly_retail_df1[ ,-(2)]

monthly_retail_df1 = monthly_retail_df1%>%
group_by(time_stamp) %>%
expand(time_stamp = seq(floor_date(time_stamp, unit = "month"),
       ceiling_date(time_stamp, unit="month")-days(1), by="day"), monthly_retail) %>% as.data.frame()


#sp index
sp_index_df = sp_index_df[ ,-(3:10)]

sp_index_df = sp_index_df%>% 
  mutate(time_stamp=mdy(date), .before= date)

sp_index_df = sp_index_df[ ,-(2)]

# merge 
shoe_data = shoe_data %>%
    left_join(monthly_retail_df, by='time_stamp') %>%
    left_join(monthly_retail_df1, by='time_stamp')%>%
    left_join(sp_index_df, by='time_stamp')

shoe_data = na.locf(shoe_data)

#team performance stuff
ncaa_teams = read.csv("data/ncaa.csv")
ncaa_teams = ncaa_teams %>%
  filter(To >= 2019 & From <= 2019) 

# aggregate teams by state
agg_ncaa = data.frame(
ncaa_teams %>%
  group_by(State) %>%
  summarise(across(c("Overall_Win_Loss_Percentage", "Win_Percentage_2019","Win_Percentage_2018", "Yrs", "AP_Rank_2019", "AP_Ranked_2018"), ~ mean(.x, na.rm = TRUE)))
,
  ncaa_teams %>%
  group_by(State) %>%
  summarise(across(c("NCAA_Tournament_Appearances", "Final_Four_Appearances","NCAA_Championships", "AP_Final_Poll_Appearances"), ~ sum(.x, na.rm = TRUE)))
)

shoe_data = merge(shoe_data, agg_ncaa, by.x = "buyer_region", by.y="State", all.x = TRUE)

#shoe characteristics
shoe_characteristics = read.csv("data/shoe_characteristics.csv")

shoe_data = merge(shoe_data, shoe_characteristics, by.x = "sneaker_name", by.y="Shoe", all.x = TRUE)


# state population and income
shoe_data = merge(shoe_data, state_pop_income, by.x = c("buyer_region","year"), by.y = c("buyer_region","year"), all.x = TRUE)


```


```{r visualizations, echo=FALSE, dpi=300}
shoe_data <- read.csv("data/shoe_final.csv")
#For the visualizations, we need to aggregate by Year-Month
shoe_data$Year_month <- format(as.Date(shoe_data$time_stamp), "%Y-%m")

#We'll look at the total sales per month and the cumulative sum for each brand over time
sales_dollars = shoe_data %>%
  group_by(brand, Year_month) %>%
  summarise(monthly_sales = sum(sale_price))
sales_dollars = sales_dollars %>%
  group_by(brand) %>%
  mutate(total_sales = cumsum(monthly_sales))


ggplot(sales_dollars) +
  geom_line(aes(x=Year_month,y=monthly_sales, group = brand, color = brand))

ggplot(sales_dollars) +
  geom_line(aes(x=Year_month,y=total_sales, group = brand, color = brand))


# Next we'll look at total sales volume (number of orders) per month as well as cumulative orders over time.

sales_vol = shoe_data %>%
  group_by(brand, Year_month) %>%
  summarise(monthly_orders = n())
sales_vol = sales_vol %>%
  group_by(brand) %>%
  mutate(total_orders = cumsum(monthly_orders))

ggplot(sales_vol) +
  geom_line(aes(x=Year_month,y=monthly_orders, group = brand, color = brand))

ggplot(sales_vol) +
  geom_line(aes(x=Year_month,y=total_orders, group = brand, color = brand))



```

We see a spike in orders during the holidays for both brands. The bulk of the orders as well as sales dollars comes from Yeezys most likely because the Adidas Yeezy shoes are cheaper on the resale market than the more exclusive Nike Off-White shoes.

```{r visualizations2, echo=FALSE, dpi=300}
shoe_data$resale_premium = shoe_data$sale_price - shoe_data$retail_price
shoe_data$resale_premium_percent = 100*(shoe_data$resale_premium / shoe_data$retail_price)

brand_premium = shoe_data %>%
  group_by(brand, Year_month) %>%
  summarise(average_premium = mean(resale_premium_percent))

ggplot(brand_premium) +
  geom_line(aes(x=Year_month,y=average_premium, group = brand, color = brand))

```
For Yeezys, buyers typically paid a ~200% premium for resale while Off-White buyers paid on average ~600%. For both brands the resale prices cooled off, but the Off-White shoes still demanded a much higher average premium throughout. We think this is the case because Adidas tends to restock their shoes much more frequently to the point where some shoes like the `adidas-Yeezy-Boost-350-V2-Butter` or the `Adidas-Yeezy-Boost-350-V2-Cream-White` resell for less than their retail price.

```{r visualizations2, echo=FALSE, dpi=300}

# We're looking at a sales premium percent change
resale_prem = shoe_data %>%
  group_by(year = year(time_stamp), buyer_region) %>%
  summarise(avg_resale_premium = mean(resale_premium_percent)) %>%
  select(state = buyer_region, year, avg_resale_premium)

total_order_count = shoe_data %>%
  group_by(year = year(time_stamp), buyer_region) %>%
  summarise(total_order_count = n()) %>%
  select(state = buyer_region, year, total_order_count)

state_pop_income = distinct(shoe_data %>%
                              group_by(buyer_region, year) %>%
                              select(year, buyer_region, State_pop_year, disposable_per_cap_income) %>%
                              arrange(buyer_region, year))

state_year_aggs = merge(merge(resale_prem, total_order_count, by = c("state", "year")), state_pop_income, by.x = c("state","year"), by.y=c("buyer_region","year"), all.x = TRUE)



## resale premium
map_1 = plot_usmap(data = state_year_aggs %>% filter(year=="2017"), values = "avg_resale_premium", color = "black") + 
  scale_fill_continuous(low = "white", high = "blue", name = "Average Resale Premium", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2017 Average Resale Premium by State")

map_2 = plot_usmap(data = state_year_aggs %>% filter(year=="2018"), values = "avg_resale_premium", color = "black") + 
  scale_fill_continuous(low = "white", high = "blue", name = "Average Resale Premium", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2018 Average Resale Premium by State")

map_3 = plot_usmap(data = state_year_aggs %>% filter(year=="2019"), values = "avg_resale_premium", color = "black") + 
  scale_fill_continuous(low = "white", high = "blue", name = "Average Resale Premium", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2019 Average Resale Premium by State")

map_1
map_2
map_3

## total orders

#column is in millions so we gotta * 1000000
state_year_aggs$State_pop_year = state_year_aggs$State_pop_year*1000000
state_year_aggs$orders_per_capita = state_year_aggs$total_order_count / state_year_aggs$State_pop_year
state_year_aggs$orders_per_10000 = 10000*(state_year_aggs$total_order_count / state_year_aggs$State_pop_year)

map_4 = plot_usmap(data = state_year_aggs %>% filter(year=="2017"), values = "orders_per_10000", color = "red") + 
  scale_fill_continuous(low = "white", high = "orange", name = "Orders", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2017 Total Order Count per 10000")

map_5 = plot_usmap(data = state_year_aggs %>% filter(year=="2018"), values = "orders_per_10000", color = "red") + 
  scale_fill_continuous(low = "white", high = "orange", name = "Orders", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2018 Total Order Count per 10000")

map_6 = plot_usmap(data = state_year_aggs %>% filter(year=="2019"), values = "orders_per_10000", color = "red") + 
  scale_fill_continuous(low = "white", high = "orange", name = "Orders", label = scales::comma) + 
  theme(legend.position = "right") + labs(title = "2019 Total Order Count per 10000")

map_4
map_5
map_6 #oregon emerges as a major sneaker buyer market

```





### Reference 
##### S&P Retail Select Industry Index
https://www.spglobal.com/spdji/en/indices/equity/sp-retail-select-industry-index/#overview

##### US Census Bureau
https://www.census.gov/retail/marts/historic_releases.html

